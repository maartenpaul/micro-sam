{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37bf194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-09-17 20:48:05.343\u001b[0m | Level 30\u001b[0m | \u001b[36mbioimageio.spec.model.v0_5\u001b[0m:\u001b[36m_validate_documentation\u001b[0m:\u001b[36m2576\u001b[0m - documentation: No '# Validation' (sub)section found in C:\\Users\\maart\\AppData\\Local\\Temp\\tmpc403_50v\\documentation.md.\u001b[0m\n",
      "\u001b[32m2025-09-17 20:48:06.023\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mbioimageio.core.backends.pytorch_backend\u001b[0m:\u001b[36mload_torch_state_dict\u001b[0m:\u001b[36m173\u001b[0m - \u001b[33m\u001b[1m`model.load_state_dict()` unexpectedly returned: None (expected named tuple with `missing_keys` and `unexpected_keys` attributes)\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"upsample_bilinear2d_out_frame\" not implemented for 'Byte'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m bioimageio_model_path = os.path.join(output_directory, \u001b[33m\"\u001b[39m\u001b[33mbioimage_io_model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#os.makedirs(bioimageio_model_path, exist_ok=True)\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Export the SAM model to bioimage.io format\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mexport_sam_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using the same model_type as in training\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicro_sam_test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbioimageio_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional: Add additional kwargs as needed\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauthors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour Name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maffiliation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour Institution\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMicro-SAM model trained on microscopy images for segmentation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlicense\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMIT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocumentation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModel trained with micro-sam for segmenting microscopy images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBioImage.IO model exported to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbioimageio_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\micro_sam\\bioimageio\\model_export.py:525\u001b[39m, in \u001b[36mexport_sam_model\u001b[39m\u001b[34m(image, label_image, model_type, name, output_path, checkpoint_path, **kwargs)\u001b[39m\n\u001b[32m    503\u001b[39m     extra_kwargs[\u001b[33m\"\u001b[39m\u001b[33mattachments\u001b[39m\u001b[33m\"\u001b[39m] = [spec.FileDescr(source=decoder_path)]\n\u001b[32m    505\u001b[39m model_description = spec.ModelDescr(\n\u001b[32m    506\u001b[39m     name=name,\n\u001b[32m    507\u001b[39m     inputs=input_descriptions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    522\u001b[39m     \u001b[38;5;66;03m# config=\u001b[39;00m\n\u001b[32m    523\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43m_check_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m save_bioimageio_package(model_description, output_path=output_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\micro_sam\\bioimageio\\model_export.py:239\u001b[39m, in \u001b[36m_check_model\u001b[39m\u001b[34m(model_description, input_paths, result_paths)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m bioimageio.core.create_prediction_pipeline(model_description) \u001b[38;5;28;01mas\u001b[39;00m pp:\n\u001b[32m    225\u001b[39m \n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# Check with all prompts. We only check the result for this setting,\u001b[39;00m\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# because this was used to generate the test data.\u001b[39;00m\n\u001b[32m    228\u001b[39m     sample = create_sample_for_model(\n\u001b[32m    229\u001b[39m         model=model_description,\n\u001b[32m    230\u001b[39m         inputs={\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m         },\n\u001b[32m    238\u001b[39m     ).as_single_block()\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     prediction = \u001b[43mpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_sample_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     predicted_mask = prediction.blocks[\u001b[33m\"\u001b[39m\u001b[33mmasks\u001b[39m\u001b[33m\"\u001b[39m].data.data\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m predicted_mask.shape == mask.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\bioimageio\\core\\_prediction_pipeline.py:139\u001b[39m, in \u001b[36mPredictionPipeline.predict_sample_block\u001b[39m\u001b[34m(self, sample_block, skip_preprocessing, skip_postprocessing)\u001b[39m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28mself\u001b[39m.apply_preprocessing(sample_block)\n\u001b[32m    138\u001b[39m output_meta = sample_block.get_transformed_meta(\u001b[38;5;28mself\u001b[39m._block_transform)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m local_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_block\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m output = output_meta.with_data(local_output.members, stat=local_output.stat)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_postprocessing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\bioimageio\\core\\backends\\_model_adapter.py:205\u001b[39m, in \u001b[36mModelAdapter.forward\u001b[39m\u001b[34m(self, input_sample)\u001b[39m\n\u001b[32m    195\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected input tensor IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munexpected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m input_arrays = [\n\u001b[32m    198\u001b[39m     (\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m in_id, in_order \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m._input_ids, \u001b[38;5;28mself\u001b[39m._input_axes)\n\u001b[32m    204\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m output_arrays = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_arrays) <= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._output_ids)\n\u001b[32m    207\u001b[39m output_tensors = [\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Tensor(a, dims=d)\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_arrays, \u001b[38;5;28mself\u001b[39m._output_axes)\n\u001b[32m    210\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\bioimageio\\core\\backends\\pytorch_backend.py:65\u001b[39m, in \u001b[36mPytorchModelAdapter._forward_impl\u001b[39m\u001b[34m(self, input_arrays)\u001b[39m\n\u001b[32m     62\u001b[39m     assert_never(\u001b[38;5;28mself\u001b[39m._mode)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctxt():\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     model_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_tuple(model_out) \u001b[38;5;129;01mor\u001b[39;00m is_list(model_out):\n\u001b[32m     68\u001b[39m     model_out_seq = model_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\tmp75zos7fx\\predictor_adaptor_c4f1b60f0f0c8581ef09f93fc01e8c3a68845d3af796d36d2a161b85cd295f81.py:74\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, image, box_prompts, point_prompts, point_labels, mask_prompts, embeddings)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\segment_anything\\utils\\transforms.py:63\u001b[39m, in \u001b[36mResizeLongestSide.apply_image_torch\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Expects an image in BCHW format. May not exactly match apply_image.\u001b[39;00m\n\u001b[32m     62\u001b[39m target_size = \u001b[38;5;28mself\u001b[39m.get_preprocess_shape(image.shape[\u001b[32m2\u001b[39m], image.shape[\u001b[32m3\u001b[39m], \u001b[38;5;28mself\u001b[39m.target_length)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbilinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\nn\\functional.py:4678\u001b[39m, in \u001b[36minterpolate\u001b[39m\u001b[34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[39m\n\u001b[32m   4676\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m antialias:\n\u001b[32m-> \u001b[39m\u001b[32m4678\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_upsample_bilinear2d_aa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4679\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\n\u001b[32m   4680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4681\u001b[39m \u001b[38;5;66;03m# Two levels are necessary to prevent TorchScript from touching\u001b[39;00m\n\u001b[32m   4682\u001b[39m \u001b[38;5;66;03m# are_deterministic_algorithms_enabled.\u001b[39;00m\n\u001b[32m   4683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting():\n",
      "\u001b[31mRuntimeError\u001b[39m: \"upsample_bilinear2d_out_frame\" not implemented for 'Byte'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "import os\n",
    "from tifffile import imread\n",
    "import imageio.v3 as imageio\n",
    "import micro_sam.util as util\n",
    "from micro_sam.bioimageio.model_export import _create_test_inputs_and_outputs\n",
    "\n",
    "# Get a test image and label to use for exporting\n",
    "# For this example, we'll use the first image and label from validation set\n",
    "test_image_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\")[0])\n",
    "test_label_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\")[0])\n",
    "output_directory = \"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\"\n",
    "# Load the test image and label\n",
    "test_image = imageio.imread(test_image_path)\n",
    "test_label = np.array(imread(test_label_path))\n",
    "model_type=\"vit_b\"\n",
    "checkpoint_name = \"micro_sam_training_20250829_135659\"\n",
    "# Define the path for saving the bioimage.io model\n",
    "bioimageio_model_path = os.path.join(output_directory, \"bioimage_io_model\")\n",
    "#os.makedirs(bioimageio_model_path, exist_ok=True)\n",
    "\n",
    "# Export the SAM model to bioimage.io format\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,  # Using the same model_type as in training\n",
    "    name=f\"micro_sam_test\",\n",
    "    output_path=bioimageio_model_path,\n",
    "    checkpoint_path=os.path.join(\n",
    "        output_directory, \"checkpoints\", checkpoint_name, \"best.pt\"\n",
    "    ),\n",
    "    # Optional: Add additional kwargs as needed\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Institution\"}],\n",
    "    description=\"Micro-SAM model trained on microscopy images for segmentation\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam for segmenting microscopy images\",\n",
    ")\n",
    "\n",
    "print(f\"BioImage.IO model exported to: {bioimageio_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0a3a4",
   "metadata": {},
   "source": [
    "normalize the input image first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2612393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m bioimageio_model_path = os.path.join(output_directory, \u001b[33m\"\u001b[39m\u001b[33mbioimage_io_model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#os.makedirs(bioimageio_model_path, exist_ok=True)\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Export the SAM model to bioimage.io format\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mexport_sam_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using the same model_type as in training\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicro_sam_test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbioimageio_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional: Add additional kwargs as needed\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauthors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour Name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maffiliation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYour Institution\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMicro-SAM model trained on microscopy images for segmentation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlicense\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMIT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocumentation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModel trained with micro-sam for segmenting microscopy images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBioImage.IO model exported to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbioimageio_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\micro_sam\\bioimageio\\model_export.py:295\u001b[39m, in \u001b[36mexport_sam_model\u001b[39m\u001b[34m(image, label_image, model_type, name, output_path, checkpoint_path, **kwargs)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tempfile.TemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[32m    294\u001b[39m     checkpoint_path, decoder_path = _get_checkpoint(model_type, checkpoint_path, tmp_dir)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     input_paths, result_paths = \u001b[43m_create_test_inputs_and_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     input_descriptions = [\n\u001b[32m    299\u001b[39m         \u001b[38;5;66;03m# First input: the image data.\u001b[39;00m\n\u001b[32m    300\u001b[39m         spec.InputTensorDescr(\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m \n\u001b[32m    403\u001b[39m     ]\n\u001b[32m    405\u001b[39m     output_descriptions = [\n\u001b[32m    406\u001b[39m         \u001b[38;5;66;03m# First output: The mask predictions.\u001b[39;00m\n\u001b[32m    407\u001b[39m         spec.OutputTensorDescr(\n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m         )\n\u001b[32m    462\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\micro_sam\\bioimageio\\model_export.py:74\u001b[39m, in \u001b[36m_create_test_inputs_and_outputs\u001b[39m\u001b[34m(image, labels, model_type, checkpoint_path, tmp_dir)\u001b[39m\n\u001b[32m     71\u001b[39m image_path = os.path.join(tmp_dir, \u001b[33m\"\u001b[39m\u001b[33minput.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m np.save(image_path, input_)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m masks, scores, embeddings = \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbox_prompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox_prompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoint_prompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_prompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_prompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_prompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m box_prompt_path = os.path.join(tmp_dir, \u001b[33m\"\u001b[39m\u001b[33mbox_prompts.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m point_prompt_path = os.path.join(tmp_dir, \u001b[33m\"\u001b[39m\u001b[33mpoint_prompts.npy\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\micro_sam\\bioimageio\\predictor_adaptor.py:80\u001b[39m, in \u001b[36mPredictorAdaptor.forward\u001b[39m\u001b[34m(self, image, box_prompts, point_prompts, point_labels, mask_prompts, embeddings)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sam.is_image_set:\n\u001b[32m     79\u001b[39m     input_ = \u001b[38;5;28mself\u001b[39m.sam.transform.apply_image_torch(image)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_torch_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_image_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.sam.orig_h, \u001b[38;5;28mself\u001b[39m.sam.orig_w = \u001b[38;5;28mself\u001b[39m.sam.original_size\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.sam.input_h, \u001b[38;5;28mself\u001b[39m.sam.input_w = \u001b[38;5;28mself\u001b[39m.sam.input_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\segment_anything\\predictor.py:88\u001b[39m, in \u001b[36mSamPredictor.set_torch_image\u001b[39m\u001b[34m(self, transformed_image, original_image_size)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.original_size = original_image_size\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.input_size = \u001b[38;5;28mtuple\u001b[39m(transformed_image.shape[-\u001b[32m2\u001b[39m:])\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m input_image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m.features = \u001b[38;5;28mself\u001b[39m.model.image_encoder(input_image)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m.is_image_set = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Maarten\\Code\\micro-sam\\.pixi\\envs\\default\\Lib\\site-packages\\segment_anything\\modeling\\sam.py:167\u001b[39m, in \u001b[36mSam.preprocess\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Normalize pixel values and pad to a square input.\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Normalize colors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m x = (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpixel_mean\u001b[49m) / \u001b[38;5;28mself\u001b[39m.pixel_std\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Pad\u001b[39;00m\n\u001b[32m    170\u001b[39m h, w = x.shape[-\u001b[32m2\u001b[39m:]\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "import os\n",
    "from tifffile import imread\n",
    "import imageio.v3 as imageio\n",
    "import micro_sam.util as util\n",
    "from micro_sam.bioimageio.model_export import _create_test_inputs_and_outputs\n",
    "\n",
    "# Get a test image and label to use for exporting\n",
    "# For this example, we'll use the first image and label from validation set\n",
    "test_image_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\")[0])\n",
    "test_label_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\")[0])\n",
    "output_directory = \"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\"\n",
    "# Load the test image and label\n",
    "test_image = imageio.imread(test_image_path)\n",
    "print(type(test_image))\n",
    "#test_image = test_image/test_image.max()  # normalizing not neccesary\n",
    "test_image = test_image.astype(\"float32\")\n",
    "print(test_image.dtype)\n",
    "test_label = np.array(imread(test_label_path))\n",
    "model_type=\"vit_b\"\n",
    "checkpoint_name = \"micro_sam_training_20250829_135659\"\n",
    "# Define the path for saving the bioimage.io model\n",
    "bioimageio_model_path = os.path.join(output_directory, \"bioimage_io_model\")\n",
    "#os.makedirs(bioimageio_model_path, exist_ok=True)\n",
    "\n",
    "# Export the SAM model to bioimage.io format\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,  # Using the same model_type as in training\n",
    "    name=f\"micro_sam_test\",\n",
    "    output_path=bioimageio_model_path,\n",
    "    checkpoint_path=os.path.join(\n",
    "        output_directory, \"checkpoints\", checkpoint_name, \"best.pt\"\n",
    "    ),\n",
    "    # Optional: Add additional kwargs as needed\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Institution\"}],\n",
    "    description=\"Micro-SAM model trained on microscopy images for segmentation\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam for segmenting microscopy images\",\n",
    ")\n",
    "\n",
    "print(f\"BioImage.IO model exported to: {bioimageio_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
